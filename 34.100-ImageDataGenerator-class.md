```python
keras.preprocessing.image.ImageDataGenerator(featurewise_center=False, samplewise_center=False, featurewise_std_normalization=False, samplewise_std_normalization=False, zca_whitening=False, zca_epsilon=1e-06, rotation_range=0, width_shift_range=0.0, height_shift_range=0.0, brightness_range=None, shear_range=0.0, zoom_range=0.0, channel_shift_range=0.0, fill_mode='nearest', cval=0.0, horizontal_flip=False, vertical_flip=False, rescale=None, preprocessing_function=None, data_format=None, validation_split=0.0, dtype=None)
```

* 通过实时数据增强生成批量张量图像数据。数据将循环（批量）。

* 参数
  * featurewise_center：布尔值。在数据集上将输入均值设置为0，具体为。
  * samplewise_center：布尔值。将每个样本均值设置为0。
  * featurewise_std_normalization：布尔值。按功能划分数据集的std输入。
  * samplewise_std_normalization：布尔值。将每个输入除以其标准。
  * zca_epsilon：用于ZCA美白的epsilon。默认值为1e-6。
  * zca_whitening：布尔值。应用ZCA美白。
  * rotation_range：Int。随机旋转的度数范围。
  * width_shift_range：Float，1-D array-like或int
    * float：总宽度的分数，如果<1，则像素> = 1。
    * 1-D数组：来自数组的随机元素。
    * int：间隔的整数像素数（-width_shift_range，+ width_shift_range）
    * 对于width_shift_range = 2，可能的值是整数[-1,0，+ 1]，与width_shift_range = [ -  1,0，+ 1]相同，而width_shift_range = 1.0可能的值是半开区间的浮点数[ - 1.0，+ 1.0 [。
  * height_shift_range：Float，1-D array-like或int
    * float：总高度的分数，如果<1，则像素> = 1。
    * 1-D数组：来自数组的随机元素。
    * int：间隔的整数像素数（-height_shift_range，+ height_shift_range）
    * 使用height_shift_range = 2可能的值是整数[-1,0，+ 1]，与height_shift_range = [ -  1,0，+ 1]相同，而在height_shift_range = 1.0的情况下，可能的值是半开区间的浮点数[ - 1.0，+ 1.0 [。
  * brightness_range：元组或两个浮点列表。从中选择亮度偏移值的范围。
  * shear_range：浮动。剪切强度（逆时针方向的剪切角度，以度为单位）
  * zoom_range：Float或[lower，upper]。随机缩放范围。如果是浮点数，[lower，upper] = [1-zoom_range，1 + zoom_range]。
  * channel_shift_range：浮动。随机频道转换的范围。
  * fill_mode：{“常量”，“最近”，“反射”或“换行”之一}。默认值为“最近”。根据给定的模式填充输入边界之外的点：
    * '常数'：kkkkkkkk | abcd | kkkkkkkk（cval = k）
    * '最近'：aaaaaaaa | abcd | dddddddd
    * 'reflect'：abcddcba | abcd | dcbaabcd
    * 'wrap'：abcdabcd | abcd | abcdabcd
  * cval：Float或Int。当fill_mode =“constant”时，用于边界外的点的值。
  * horizontal_flip：布尔值。水平随机翻转输入。
  * vertical_flip：布尔值。随机垂直翻转输入。
  * rescale：重新缩放因子。默认为无。如果为None或0，则不应用重新缩放，否则我们将数据乘以提供的值（在应用所有其他变换之后）。
  * preprocessing_function：将隐含在每个输入上的函数。该图像调整大小并增强后，将运行该功能。该函数应该采用一个参数：一个图像（Numpy张量为3级），并应输出具有相同形状的Numpy张量
  * data_format：图像数据格式，“channels_first”或“channels_last”。 “channels_last”模式意味着图像应具有形状（样本，高度，宽度，通道），“channels_first”模式意味着图像应具有形状（样本，通道，高度，宽度）。它默认为〜/ .keras / keras.json中Keras配置文件中的image_data_format值。如果你从未设置它，那么它将是“channels_last”。
  * validation_split：Float。保留用于验证的图像的分数（严格地在0和1之间）。
  * dtype：用于生成的数组的Dtype。





## **Examples**

### Example of using `.flow(x, y)`:

```python
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
y_train = np_utils.to_categorical(y_train, num_classes)
y_test = np_utils.to_categorical(y_test, num_classes)

datagen = ImageDataGenerator(
    featurewise_center=True,
    featurewise_std_normalization=True,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True)

# compute quantities required for featurewise normalization
# (std, mean, and principal components if ZCA whitening is applied)
datagen.fit(x_train)

# fits the model on batches with real-time data augmentation:
model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),
                    steps_per_epoch=len(x_train) / 32, epochs=epochs)

# here's a more "manual" example
for e in range(epochs):
    print('Epoch', e)
    batches = 0
    for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):
        model.fit(x_batch, y_batch)
        batches += 1
        if batches >= len(x_train) / 32:
            # we need to break the loop by hand because
            # the generator loops indefinitely
            break
```



### Example of using `.flow_from_directory(directory)`:

```python
train_datagen = ImageDataGenerator(
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
        'data/train',
        target_size=(150, 150),
        batch_size=32,
        class_mode='binary')

validation_generator = test_datagen.flow_from_directory(
        'data/validation',
        target_size=(150, 150),
        batch_size=32,
        class_mode='binary')

model.fit_generator(
        train_generator,
        steps_per_epoch=2000,
        epochs=50,
        validation_data=validation_generator,
        validation_steps=800)
```



### Example of transforming images and masks together.

```python
# we create two instances with the same arguments
data_gen_args = dict(featurewise_center=True,
                     featurewise_std_normalization=True,
                     rotation_range=90,
                     width_shift_range=0.1,
                     height_shift_range=0.1,
                     zoom_range=0.2)
image_datagen = ImageDataGenerator(**data_gen_args)
mask_datagen = ImageDataGenerator(**data_gen_args)

# Provide the same seed and keyword arguments to the fit and flow methods
seed = 1
image_datagen.fit(images, augment=True, seed=seed)
mask_datagen.fit(masks, augment=True, seed=seed)

image_generator = image_datagen.flow_from_directory(
    'data/images',
    class_mode=None,
    seed=seed)

mask_generator = mask_datagen.flow_from_directory(
    'data/masks',
    class_mode=None,
    seed=seed)

# combine generators into one which yields image and masks
train_generator = zip(image_generator, mask_generator)

model.fit_generator(
    train_generator,
    steps_per_epoch=2000,
    epochs=50)
```

